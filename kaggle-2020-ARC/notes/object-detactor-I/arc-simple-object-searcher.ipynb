{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [ARC] Simple Object Searcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "import os, shutil\n",
    "import json\n",
    "from pathlib import Path\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from fastai.vision import *\n",
    "from fastai.utils.mod_display import *\n",
    "from torchvision import utils\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn import metrics\n",
    "\n",
    "from fastai.callbacks.hooks import *\n",
    "from fastai.utils.mem import *\n",
    "from fastai.utils.mod_display import *\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_input_path = '/kaggle/input'\n",
    "\n",
    "kaggle_arc_path = '/arc/input'\n",
    "\n",
    "\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "#for dirname, _, filenames in os.walk(kaggle_input_path):\n",
    "#    print(dirname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "data_path = Path(kaggle_input_path+'/abstraction-and-reasoning-challenge/')\n",
    "training_path = data_path / 'training'\n",
    "evaluation_path = data_path / 'evaluation'\n",
    "test_path = data_path / 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_sample_arr(taskname, test_train = 'train', in_out = 'input', idx = 0, path=training_path):\n",
    "    task_file = str(path / (taskname+'.json'))\n",
    "    with open(task_file, 'r') as f:\n",
    "        task = json.load(f)\n",
    "    \n",
    "    return np.array(task[test_train][idx][in_out])\n",
    "\n",
    "\n",
    "def load_task(taskname, path=training_path):\n",
    "    task_file = str(path / (taskname+'.json'))\n",
    "    with open(task_file, 'r') as f:\n",
    "        task = json.load(f)\n",
    "    \n",
    "    return task\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to plot task\n",
    "Modified version of plot_task from https://www.kaggle.com/inversion/abstraction-and-reasoning-starter-notebook.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = colors.ListedColormap(\n",
    "        ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n",
    "         '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25' ,'#FFFFFF'])\n",
    "\n",
    "cnorm = colors.Normalize(vmin=0, vmax=10) #vmax=9\n",
    "\n",
    "def plot_task(taskname, path = training_path, pred_imgs=[], max_train = -1):\n",
    "    \"\"\"\n",
    "    Plots the first train and test pairs of a specified task,\n",
    "    using same color scheme as the ARC app\n",
    "    \"\"\"\n",
    "    \n",
    "    # loading tasks\n",
    "    task_file = str(path / (taskname+'.json'))\n",
    "    with open(task_file, 'r') as f:\n",
    "        task = json.load(f)\n",
    "    \n",
    "    if len(pred_imgs) == 0:\n",
    "        rows = 2\n",
    "    else:\n",
    "        rows = 4\n",
    "    \n",
    "    if max_train == -1:\n",
    "        # show all\n",
    "        max_train = len(task['train'])  \n",
    "    \n",
    "    fig, axs = plt.subplots(rows, (max_train+len(task['test']))*2, figsize=(15,2*rows))\n",
    "    offset = 0\n",
    "    for i in range(max_train):\n",
    "        axs[0, i*2].imshow(task['train'][i]['input'], cmap=cmap, norm=cnorm)\n",
    "        axs[0, i*2].axis('off')\n",
    "        axs[0, i*2].set_title('Train In '+str(i))\n",
    "        \n",
    "        axs[0, i*2+1].imshow(task['train'][i]['output'], cmap=cmap, norm=cnorm)\n",
    "        axs[0, i*2+1].axis('off')\n",
    "        axs[0, i*2+1].set_title('Train Out '+str(i))\n",
    "        \n",
    "        offset+=2\n",
    "        \n",
    "    for i in range(len(task['test'])):\n",
    "        j=i*2+offset\n",
    "        axs[0, j].imshow(task['test'][i]['input'], cmap=cmap, norm=cnorm)\n",
    "        axs[0, j].set_title('Valid In '+str(i))\n",
    "        axs[0, j].axis('off')\n",
    "        \n",
    "        axs[0, j+1].imshow(task['test'][i]['output'], cmap=cmap, norm=cnorm)\n",
    "        axs[0, j+1].set_title('Valid Out '+str(i))\n",
    "        axs[0, j+1].axis('off')\n",
    "            \n",
    "    if rows == 4:\n",
    "        for p, pred_img in enumerate(pred_imgs):\n",
    "            y = -2*(len(pred_imgs))+2*p+1\n",
    "            axs[1, y].imshow(pred_img, cmap=cmap, norm=cnorm)\n",
    "            axs[1, y].set_title('Pred img')\n",
    "            #for i in range(len(task['test'])+max_train*2):\n",
    "            #    axs[2, i ].axis('off')\n",
    "\n",
    "            rs_pred_img = pred_img.astype('int8')\n",
    "            #     resize_unpad(pred_img,task_info[taskname]['max_xy'],\n",
    "            #                           np.round(task_info[taskname]['test_in_shapes'][p] * \n",
    "            #                                    task_info[taskname]['avg_train_shape_factor'])\n",
    "            #                          )\n",
    "            #acc = metrics.accuracy_score(np.array(task['test'][p]['output']).reshape(1,-1)[0], rs_pred_img.reshape(1,-1)[0])\n",
    "        \n",
    "            axs[2, y].imshow(rs_pred_img, cmap=cmap, norm=cnorm)\n",
    "            axs[2, y].set_title(f'Pred img croped and rescaled (acc: {acc:.4f})')\n",
    "        \n",
    "        for i in range((len(task['test'])+max_train)*2):\n",
    "            axs[1, i].axis('off')\n",
    "            axs[2, i].axis('off')\n",
    "                \n",
    "        #acc = metrics.accuracy_score(np.array(task['test'][0]['output']).reshape(1,-1)[0], rs_pred_img.reshape(1,-1)[0])\n",
    "        #print(f\"Accuracy: {acc}\")\n",
    "                \n",
    "    plt.tight_layout()\n",
    "    #plt.savefig(f'{kaggle_arc_path}/temp/output/eval_{taskname}.png', dpi=None, facecolor='w', edgecolor='w',orientation='landscape')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABC0AAAEYCAYAAAB4AwyyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3df5BlZ1kn8O9jxhD5DSa7YBJIWAbYYCnoLLJQq1GwTFglrGI2uCAomEINlgqyaBBCNLqiWyiCSBAMIAIBUYILRhRYl12CTEoIBAgOAcwQkCGEYATDD9/9456Bm07P9O3u033fPvP5VE3Nvee+57zPvfOdM3eePj+qtRYAAACA3nzdsgsAAAAAWI2mBQAAANAlTQsAAACgS5oWAAAAQJc0LQAAAIAuaVoAAAAAXdK0AGDyqupNVfXYZdcBi5JZpqSqWlXdc3j8+1X1y4uMhWWR2b5oWgDQpaq6ce7Xv1bVF+ae/7f1bKu1dnpr7aUbrOOjVfXQDa57TlXtraqbquqijWyDnaOXzA61PK6q3ltVn6+qT1bVC6rqjutY/7C5r6qjq+q1w7hWVadutFb6V1WXVtX5qyw/Y8jXrkW31Vp7YmvtVzZYx9uq6gkbXPdWVfWSqvrcUPPPb2Q77Ay9ZHaY8/ur6m+r6p+r6rqqekVVnbCO9dfMfVXdr6ouH/b5l1fV/TZab480LQDoUmvttgd/JfmHJD8wt+wVB8et54vHElyb5FeTvGTZhbD1eslsVT05yW8k+YUkd0jywCR3T/Lmqjp6xKnenuTRST454jbp00VJHlNVtWL5Y5K8orX25e0vad3OS7I7s78L353kqVV12lIrYitdlA4yW1WPTPLHSX4nybFJ7pvkpiRvr6o7jTTH0Ulen+SPktwpyUuTvH7k/f1SaVoAsKNU1alVtb+q/ntVfTLJH1bVnarqz6vqQFVdPzw+YW6dr/6UYvgJ9Nur6reGsR+pqtMXnHtd67bWXtda+7Mk1232fbNzbWdmq+r2SZ6V5Emttb9orX2ptfbRJGdm9p+1Rw/jLqqqX11Z4/D45UnuluQNw1EiT105T2vti621326tvT3JV8b5pOjYnyW5c5L/dHDB8B+u70/ysqp6QFW9o6o+W1WfqKrnHeo/TKtk7xeGda6tqh9ftKC5v1dPrqpPDdv4scOs8qNJfqW1dn1r7QNJXpTkcYvOx46z9MwODZP/meRXW2uvaK19obX2ySRPSHJjkp8bxp1XVX80t95JNTuCbVdVXTC8h+cN++PnrTLVqUl2Jfnt1tpNrbXnJqkk37PQJ7UDaFoAsBPdJbMvI3dPcnZm/5794fD8bkm+kGS1f9gP+o4kV2X2U49nJ3nxKj+N2Yp1OXJtV2YflOSYJK+bX9hauzHJm5J871qFttYek5sfKfLstdZh2lprX0hycWb/8T/ozCQfbK29J7PG1c9lls//mOQhSX5qre0ORzo8JbNc7k6y3lPx7pLZ0UTHJ3l8kuev9tPrYdk3JXnP3OL3ZPZTbyaok8zeO7P9+2tW1PavSf4ki+2Pz03yf5KcM+yPz1ll2H2TXNFaa3PLrsiE8q1pAcBO9K9Jnjn8ROELrbXrWmt/0lr7fGvtn5JckOS7DrP+x1prL2qtfSWzwyjvmuTfLjj3ZtblyLVdmT02yacPcejzJ4bXYSNemuSHq+obhuc/OixLa+3y1tplrbUvD0f2vDCHz/NBZyb5w9ba+1pr/5zZKRzr8aUk5w9HFL0xs59e33uVcbcdfr9hbtkNSW63zvnYWZad2YP720+s8tqY++Pb5ubZTiaWb00LAHaiA621fzn4pKpuXVUvrKqPVdXnkvxNkjtW1VGHWP+r5+C31j4/PLztIcaOuS5Hru3K7KeTHHuI62bcdXgd1m04FehAkjOq6h5J/kNm5+qnqu41nOL0ySHPv5bF/kP2TUmumXv+sXWWdd2KBt3ns/rfixuH328/t+z2Sf5pnfOxg3SQ2YP727uu8tqY++Mbc/NsJxPLt6YFADtRW/H8yZn9dO07Wmu3T/Kdw3KnbdCL7crsOzK7yNsPzi+sqtskOT3JXw+L/jnJreeG3GWNeiFJXpbZT6sfk+QvW2v/OCx/QZIPJtk95PmXsliWP5HkxLnndxux1q9qrV0/zPWtc4u/NcmVWzEfXVlmZq9Ksj/JD88vrKqvS/JDGW9/fGWSb1lxyuC3ZEL51rTYIuX+6uwwMssOd7vMrgnw2aq6c5JnLrmeJLO7RFTVMUmOSnJUVR1ziJ+Ac+TZksy21m7I7EKcv1tVp1XV11fVSZmdU70/ycuHoe9O8rCqunNV3SXJz67Y1D8mucfh5qrZLSSPGZ4ePeRbo3DaXpbZOfw/keEw+8HtknwuyY1VdZ8kP7ng9i5O8riqOqWqbp2t3Xe/LMnTh4vg3iez93DRFs5HH5aW2eEaE0/JLHc/UlXfMOxv/yCzIyGeMwx9d5LvrKq7VdUdkvziik2ttT9+W2bX6PiZYb988LoXb1nwPXVP02JOdXJ/9Vrj3uhrrHvnqvrTmt0H+GNV9SMb2Q47Qy+ZHWp5XFW9t2b3h/5kVb2gqu64jvXXzH1VPaSqPjjM8daquvtG62VyfjvJN2R2qOVlSf5iueV81dMz+4/p0zK7a8MXhmWwZZkdLpz5S0l+K7Mv5e/M7HDmh7TWbhqGvTyzCxF+NMlfJnn1is38emZftD9bVU85xFRXZZbp45NcOjy2X56w4dz//5fkNkkumXvpKUl+JLPD0V+UW+bpUNt7U2Z/F96SZF+29j9Zz0zy4cwO5//fSX6ztdbLvxVskWVntrX26syO8vi5zPb3789s3//g1tp1w5g3D/NfkeTyJH++YjO/k+SRNbt71HNXmeOLSR6R2REln03y40keMSyfhLr5RUY5qKo+muQJrbW/WuW1XVt5b9/Dzb3Auq/MrBn1+CT3S/K/kjyotTaZw4NY3ZIz++QkT03y2MwOdTs+ye8lOS6znfKaO821cl9Vx2b2ZeMJSd6Q5FeS/KfW2gPHeA8AAEB/HGmxgNrG+6uvMvd67s1+m8zOj/rl1tqNw8VnLsmsu8cRZDszW1W3z+xQ5Ce11v5iuIL3RzO7uvLdM/vp8mr3uD61qvYPj1+e2TmBbxiOEnnqKlP9YJIrW2uvGS5md16Sbx0O6QMAACZI02Jx23V/9c2se68kX2mtfWhumXtQH7m2K7MPSnJMktfNL2yt3ZjkTVnsHtSPSfIPSX5guAf1s1cZdt/M3V99uM3UhyPfAAAwWZoWi9uu+6tvZt3J36OXddmuzB6b5NOHOP3EPagBAIANcwXzxd3i/uqZXfH1tCR3GhbfrqqOGv6Tt9LN7q8+/MB6tftIr2bRdSd/j17WZbsy++kkxx7iuhnuQQ0AAGyYpsXiDnd/9U9W1f2S/F02f3/1zfhQkl1Vtbu19vfDMvegPnJtV2bfkeSmzK45cfHBhcM1Vk7P7Ar2yTj3oP7qLVmH7f+7yPeoqmppV2duFxy/qfXr3I+PVMmRpbU2vVtU/toJm8rxeWfu3/i6F5+w9qAJzr3Z+Tf793eSOV7DMvfXy7Lefyd6/HfhSMzqWs7bt+Z3wJuPX+e+ZiP7tq2eYxLv4Z7b9/9ep4ds3JbcX30zhnP8X5fk/Kq6TVU9OMkZ+do92TmybUlmW2s3ZHYhzt+tqtOq6uur6qQkr0myP1/L37uTPGy4Le9dkvzsik2tdQ/qP03yzVX1Q1V1TJJnJLmitfbBMd4HAADQH02Ljduy+6tv0k9lVtenkrwyyU+63SmDLcvscOHMX0ryW0k+l+SdSa5J8pDW2k3DsJdndiHNjyb5y9zyfti/nuTpVfXZqnrKKnMcyOzuOBckuT6zC4WeNdZ7AAAA+uP0kENorZ009/htSU5Y8fq1SU5dsdoL514/de7xRUkuWrH+IQ+nWTH3etf9TJJHHOp1pmuZmR1ef3GSFx/m9X9J8l9XLH7O3OuvT/L6Neb4qyRucQoAAEcIR1oAAAAAXdK0AAAAALqkaQEAAAB0SdMCAAAA6JKmBQAAANClpd09pKrasubeDu2C40fbVp378dG21aO17krRs/P2ZbQcn3fxCWsPWmQ7Z+4fZTvJeDUlfdY1ak33zI7NMQAA9MqRFgAAAECXNC0AAACALmlaAAAAAF3StAAAAAC6pGkBAAAAdEnTAgAAAOjS0m55CgDAdEz9Fu0ALIcjLQAAAIAuaVoAAAAAXdK0AAAAALqkaQEAAAB0SdMCAAAA6JKmBQAAANAlTQsAAACgS7uWXQAAAABHpmftrnWNP++C47eoEnrlSAsAAACgS5oWAAAAQJecHgKbsN7D2Q7HoW7bb9Q/v9ZG2xYAADDjSAsAAACgS5oWAAAAQJc0LQAAAIAuuaYFAACjXucHAMbiSAsAAACgS5oWAAAAQJc0LQAAAIAuaVoAAAAAXdK0AAAAALrk7iEAAADsCHXux9c1/plnblEhbBtHWgAAAABd0rQAAAAAuqRpAQAAAHRJ0wIAAADokqYFAAAA0CVNCwAAAKBLmhYAAABAlzQtAAAAgC7tWnYBwEyd+/FRtvPMM0fZTNfG+qwAAIC+aVoAAJOy2cbmTm3+augCMEVODwEAAAC65EgLAAAAJulZu2vd65x3wfFbUEnf1vs5ndfaFlVyS460AAAAALqkaQEAAAB0SdMCAAAA6JKmBQAAANAlTQsAAACgS5oWAAAAQJc0LQAAAIAuaVoAAAAAXdK0AAAAALqkaQEAAAB0SdMCAAAA6NKuZRcAAAAAvahzP76u8c88c4sK2YT1voeeOdICAAAA6JIjLQAA5jxrd2143fMuOH5pcwPAFGlawMSM+YV3s1++5/kiDgAArJfTQwAAAIAuaVoAAAAAXdK0AAAAALqkaQEAAAB0SdMCAAAA6JKmBQAAANAlTQsAAACgS5oWAAAAQJd2LbsAAAAA2KmetbvWNf68C47f0u1PjSMtAAAAgC5pWgAAAABd0rQAAAAAuqRpAQAAAHRJ0wIAAADokruHANCFOvfjyy4BNk2OAWBcjrQAAAAAuqRpAQAAAHRJ0wIAAADokmtabBHntDIFcgwAACyTIy0AAACALmlaAAAAAF2q1tpyJq5azsR0p7VWy65ho+SYg3ZyjufJ9JFnKtmdJ8dHninmeC1yvjMdiVldiyzvTNuZZUdaAAAAAF3StAAAAAC6pGkBAAAAdEnTAgAAAOiSpgUAAADQJU0LAAAAoEuaFgAAAECXNC0AAACALmlaAAAAAF3StAAAAAC6pGkBAAAAdEnTAgAAAOiSpgUAAADQJU0LAAAAoEuaFgAAAECXdi1r4tZaLWtuGIscAwAAbB1HWgAAAABd0rQAAAAAuqRpAQAAAHRJ0wIAAADokqYFAAAA0CVNCwAAAKBLmhYAAABAl6q1tuwaAAAAAG7BkRYAAABAlzQtAAAAgC5pWgAAAABd0rQAAAAAuqRpAQAAAHRJ0wIAAADokqYFAAAA0CVNCwAAAKBLmhYAAABAlzQtAAAAgC6t2bSoqpdU1aeq6n2HeL2q6rlVta+qrqiqbxu/TNg8WWYK5JgpkGOmQI6ZAjlmJ1jkSIuLkpx2mNdPT7J7+HV2khdsvizYEhdFltn5Loocs/NdFDlm57socszOd1HkmM6t2bRorf1Nks8cZsgZSV7WZi5LcsequutYBcJYZJkpkGOmQI6ZAjlmCuSYnWCMa1ocn+Sauef7h2Ww08gyUyDHTIEcMwVyzBTIMUu3a4Rt1CrL2qoDq87O7LCi3OY2t/n2+9znPiNMz052+eWXf7q1dtyy6xgslGU5ZiU5Zio6yrLvFmyYHDMFcswUjJXjMZoW+5OcOPf8hCTXrjawtXZhkguTZM+ePW3v3r0jTM9OVlUfW3YNcxbKshyzkhwzFR1l2XcLNkyOmQI5ZgrGyvEYp4dckuRHhyvLPjDJDa21T4ywXdhusswUyDFTIMdMgRwzBXLM0q15pEVVvTLJqUmOrar9SZ6Z5OuTpLX2+0nemORhSfYl+XySH9uqYmEzZJkpkGOmQI6ZAjlmCuSYnWDNpkVr7VFrvN6S/PRoFcEWkWWmQI6ZAjlmCuSYKZBjdoIxTg8BAAAAGJ2mBQAAANAlTQsAAACgS5oWAAAAQJc0LQAAAIAuaVoAAAAAXdK0AAAAALqkaQEAAAB0SdMCAAAA6JKmBQAAANAlTQsAAACgS5oWAAAAQJc0LQAAAIAuLdS0qKrTquqqqtpXVU9b5fW7VdVbq+rvquqKqnrY+KXC5sgxUyDHTIUsMwVyzBTIMb1bs2lRVUcleX6S05OckuRRVXXKimFPT3Jxa+3+Sc5K8ntjFwqbIcdMgRwzFbLMFMgxUyDH7ASLHGnxgCT7WmtXt9a+mORVSc5YMaYluf3w+A5Jrh2vRBiFHDMFcsxUyDJTIMdMgRzTvUWaFscnuWbu+f5h2bzzkjy6qvYneWOSJ622oao6u6r2VtXeAwcObKBc2DA5ZgrkmKmQZaZAjpkCOaZ7izQtapVlbcXzRyW5qLV2QpKHJXl5Vd1i2621C1tre1pre4477rj1VwsbJ8dMgRwzFbLMFMgxUyDHdG+RpsX+JCfOPT8htzwk6PFJLk6S1to7khyT5NgxCoSRyDFTIMdMhSwzBXLMFMgx3VukafGuJLur6uSqOjqzi69csmLMPyR5SJJU1b/PLMiOCaIncswUyDFTIctMgRwzBXJM99ZsWrTWvpzknCSXJvlAZleOvbKqzq+qhw/DnpzkJ6rqPUlemeRxrbWVhxXB0sgxUyDHTIUsMwVyzBTIMTvBrkUGtdbemNlFV+aXPWPu8fuTPHjc0mBccswUyDFTIctMgRwzBXJM7xY5PQQAAABg22laAAAAAF3StAAAAAC6pGkBAAAAdEnTAgAAAOiSpgUAAADQJU0LAAAAoEuaFgAAAECXNC0AAACALmlaAAAAAF3StAAAAAC6pGkBAAAAdEnTAgAAAOjSQk2Lqjqtqq6qqn1V9bRDjDmzqt5fVVdW1R+PWyZsnhwzBXLMFMgxUyHLTIEc07tdaw2oqqOSPD/J9ybZn+RdVXVJa+39c2N2J/nFJA9urV1fVf9mqwqGjZBjpkCOmQI5ZipkmSmQY3aCRY60eECSfa21q1trX0zyqiRnrBjzE0me31q7Pklaa58at0zYNDlmCuSYKZBjpkKWmQI5pnuLNC2OT3LN3PP9w7J590pyr6r6v1V1WVWdttqGqursqtpbVXsPHDiwsYphY+SYKZBjpmC0HCeyzFLZJzMFckz3Fmla1CrL2ornu5LsTnJqkkcl+YOquuMtVmrtwtbantbanuOOO269tcJmyDFTIMdMwWg5TmSZpbJPZgrkmO4t0rTYn+TEuecnJLl2lTGvb619qbX2kSRXZRZs6IUcMwVyzBTIMVMhy0yBHNO9RZoW70qyu6pOrqqjk5yV5JIVY/4syXcnSVUdm9khRFePWShskhwzBXLMFMgxUyHLTIEc0701mxattS8nOSfJpUk+kOTi1tqVVXV+VT18GHZpkuuq6v1J3prkF1pr121V0bBecswUyDFTIMdMhSwzBXLMTlCtrTxlaXvs2bOn7d27dylz04+qury1tmfZdWyUHJPIMdMhy0yBHDMFcswUjJXjRU4PAQAAANh2mhYAAABAlzQtAAAAgC5pWgAAAABd0rQAAAAAuqRpAQAAAHRJ0wIAAADokqYFAAAA0CVNCwAAAKBLmhYAAABAlzQtAAAAgC5pWgAAAABd0rQAAAAAurRQ06KqTquqq6pqX1U97TDjHllVrar2jFcijEOOmQI5ZipkmSmQY6ZAjundmk2LqjoqyfOTnJ7klCSPqqpTVhl3uyQ/k+SdYxcJmyXHTIEcMxWyzBTIMVMgx+wEixxp8YAk+1prV7fWvpjkVUnOWGXcryR5dpJ/GbE+GIscMwVyzFTIMlMgx0yBHNO9RZoWxye5Zu75/mHZV1XV/ZOc2Fr788NtqKrOrqq9VbX3wIED6y4WNkGOmQI5ZipkmSmQY6ZAjuneIk2LWmVZ++qLVV+X5DlJnrzWhlprF7bW9rTW9hx33HGLVwmbJ8dMgRwzFbLMFMgxUyDHdG+RpsX+JCfOPT8hybVzz2+X5JuTvK2qPprkgUkucYEWOiPHTIEcMxWyzBTIMVMgx3RvkabFu5LsrqqTq+roJGclueTgi621G1prx7bWTmqtnZTksiQPb63t3ZKKYWPkmCmQY6ZClpkCOWYK5Jjurdm0aK19Ock5SS5N8oEkF7fWrqyq86vq4VtdIIxBjpkCOWYqZJkpkGOmQI7ZCXYtMqi19sYkb1yx7BmHGHvq5suC8ckxUyDHTIUsMwVyzBTIMb1b5PQQAAAAgG2naQEAAAB0SdMCAAAA6JKmBQAAANAlTQsAAACgS5oWAAAAQJc0LQAAAIAuaVoAAAAAXdK0AAAAALqkaQEAAAB0SdMCAAAA6JKmBQAAANAlTQsAAACgSws1LarqtKq6qqr2VdXTVnn956vq/VV1RVX9dVXdffxSYXPkmCmQY6ZAjpkKWWYK5Jjerdm0qKqjkjw/yelJTknyqKo6ZcWwv0uyp7X2LUlem+TZYxcKmyHHTIEcMwVyzFTIMlMgx+wEixxp8YAk+1prV7fWvpjkVUnOmB/QWntra+3zw9PLkpwwbpmwaXLMFMgxUyDHTIUsMwVyTPcWaVocn+Sauef7h2WH8vgkb1rthao6u6r2VtXeAwcOLF4lbJ4cMwVyzBSMluNEllkq+2SmQI7p3iJNi1plWVt1YNWjk+xJ8purvd5au7C1tqe1tue4445bvErYPDlmCuSYKRgtx4kss1T2yUyBHNO9XQuM2Z/kxLnnJyS5duWgqnpoknOTfFdr7aZxyoPRyDFTIMdMgRwzFbLMFMgx3VvkSIt3JdldVSdX1dFJzkpyyfyAqrp/khcmeXhr7VPjlwmbJsdMgRwzBXLMVMgyUyDHdG/NpkVr7ctJzklyaZIPJLm4tXZlVZ1fVQ8fhv1mktsmeU1VvbuqLjnE5mAp5JgpkGOmQI6ZCllmCuSYnWCR00PSWntjkjeuWPaMuccPHbkuGJ0cMwVyzBTIMVMhy0yBHNO7RU4PAQAAANh2mhYAAABAlzQtAAAAgC5pWgAAAABd0rQAAAAAuqRpAQAAAHRJ0wIAAADokqYFAAAA0CVNCwAAAKBLmhYAAABAlzQtAAAAgC5pWgAAAABd0rQAAAAAurRQ06KqTquqq6pqX1U9bZXXb1VVrx5ef2dVnTR2obBZcswUyDFTIctMgRwzBXJM79ZsWlTVUUmen+T0JKckeVRVnbJi2OOTXN9au2eS5yT5jbELhc2QY6ZAjpkKWWYK5JgpkGN2gkWOtHhAkn2ttatba19M8qokZ6wYc0aSlw6PX5vkIVVV45UJmybHTIEcMxWyzBTIMVMgx3Rv1wJjjk9yzdzz/Um+41BjWmtfrqobknxjkk/PD6qqs5OcPTy9qaret5GiR3RsVtR4hM3fQw333qZ55Hi68/dQgxxv3rL/DHuoYdnzJ7K8WT38GS67hmXPn8jxZvXwZ6gGOR7Dsv8Mlz1/DzWMkuNFmharddHaBsaktXZhkguTpKr2ttb2LDD/lll2Dcuev4caqmrvdk21yjI5nsD8PdQgx5unhuXPf7CG7ZpqlWU7PsvLnr+HGpY9/8EatmuqVZbJsRpGm3+7plpl2Y7PcQ81LHv+HmoYK8eLnB6yP8mJc89PSHLtocZU1a4kd0jymTEKhJHIMVMgx0yFLDMFcswUyDHdW6Rp8a4ku6vq5Ko6OslZSS5ZMeaSJI8dHj8yyVtaa7fovsESyTFTIMdMhSwzBXLMFMgx3Vvz9JDhvKVzklya5KgkL2mtXVlV5yfZ21q7JMmLk7y8qvZl1nU7a4G5L9xE3WNZdg3Lnj9Zfg3bMr8cT3r+ZPk1yPHmqWH58yeyvFnLnj9Zfg3Lnj+R481a9vyJGrZt/gnnOFl+DcueP1l+DaPMX5pkAAAAQI8WOT0EAAAAYNtpWgAAAABd2pKmRVWdVlVXVdW+qnraKq/fqqpePbz+zqo6ae61XxyWX1VV37dF8/98Vb2/qq6oqr+uqrvPvfaVqnr38GvlRWjGrOFxVXVgbq4nzL322Kr6++HXY1euO9L8z5mb+0NV9dm51zb9GVTVS6rqU4e6P3PNPHeo74qq+ra51zb9/scgx3I8bGdHZ3nZOV6whi3N8rJzvGAN9smHIcdyPGxDjnd4jhesYdLfLXZ6joc6fEeW4+3NcWtt1F+ZXcDlw0nukeToJO9JcsqKMT+V5PeHx2clefXw+JRh/K2SnDxs56gtmP+7k9x6ePyTB+cfnt+4TZ/B45I8b5V175zk6uH3Ow2P7zT2/CvGPymzi+6M+Rl8Z5JvS/K+Q7z+sCRvyuy+zw9M8s6x3r8cy/FYn8FOz/Kyc9xDlped416yLMdyLMdyvOwc95BlOd75WZbjIzPHW3GkxQOS7GutXd1a+2KSVyU5Y8WYM5K8dHj82iQPqaoalr+qtXZTa+0jSfYN2xt1/tbaW1trnx+eXpbZ/YjHtMhncCjfl+TNrbXPtNauT/LmJKdt8fyPSvLKdc5xWK21v8nh7998RpKXtZnLktyxqu6acd7/GORYjpPs+CwvO8cL1bDFWV52jjdSg33yzcmxHCeR4wnkeKEaDmMS3y12eI6T5WdZjo/AHG9F0+L4JNfMPd8/LFt1TGvty0luSPKNC647xvzzHp9ZF+igY6pqb1VdVlWPWOfc663hh4bDZV5bVSeuc90x5s9wuNTJSd4yt3iMz2CjNY7x/scgx3K8qJ6zvOwcL1rDvLGzvOwcr2s79smrkmM53myNcrx4DfN8t5Dj1Sw7y3J8BOZ416ilzdQqy9qCYxZZd4z5ZwOrHp1kT5Lvmlt8t9batVV1jyRvqar3ttY+vAU1vCHJK1trN1XVEzPrRn7Peurf5PwHnZXkta21r8wtG+Mz2GiNY7z/McixHC+q5ywvO8eL1jAbuDVZXnaOF63hIPvkW5JjOd5sjXK8eA2zgb5bJHJ8KMvOshwfgTneiiMt9ic5ce75CUmuPdSYqtqV5A6ZHV6yyLpjzJ+qemiSc5M8vLV208HlrcS5u8sAAAHmSURBVLVrh9+vTvK2JPdf5/wL1dBau25u3hcl+fb11L/Z+eeclRWHC430GazlUDWO8f7HIMdyvKies7zsHC9aw1Zmedk5Xu927JNvSY7leFFyvPkafLf4Gjle3bKzLMdHYo7b+Bdn2ZXZBTVOztcuDHLfFWN+Oje/OMvFw+P75uYXZ7k66784yyLz3z+zi5fsXrH8TkluNTw+Nsnf5zAXNdlkDXede/xfklzWvnZxko8MtdxpeHznsecfxt07yUeT1NifwbD+STn0xVn+c25+cZa/Hev9y7Ecj5njnZzlZee4hywvO8c9ZVmO5ViO5XiZOe4hy3K887Msx0dmjrcqzA9L8qEhLOcOy87PrNOVJMckeU1mF1/52yT3mFv33GG9q5KcvkXz/1WSf0zy7uHXJcPyByV57/AH/94kj9/Cz+DXk1w5zPXWJPeZW/fHh89mX5If24r5h+fnJfkfK9Yb5TPIrKP3iSRfyqyj9vgkT0zyxOH1SvL8ob73Jtkz5vuXYzke8TPY0Vledo57yPKyc9xDluVYjuVYjnvIcQ9ZluOdn2U5PvJyXMOKAAAAAF3ZimtaAAAAAGyapgUAAADQJU0LAAAAoEuaFgAAAECXNC0AAACALmlaAAAAAF3StAAAAAC69P8BIav3JYkY86AAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1080x288 with 12 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "taskname = 'db3e9e38' #'ae58858e'\n",
    "plot_task(taskname, path = training_path) #training_path #evaluation_path)#, max_train=2)\n",
    "\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_gen(kernel, ignore_dir = True):\n",
    "    \"\"\"\n",
    "    Generic kernel function. Adds distortion if ignore_dir = False, which causes the direction of the object being relevant:\n",
    "    \n",
    "        ignore_dir == True:\n",
    "            \n",
    "            xxxx               xxx\n",
    "             xxx   is equals   xxxx\n",
    "        \n",
    "        ignore_dir == False:\n",
    "        \n",
    "            xxxx                   xxx\n",
    "             xxx   is not equals   xxxx\n",
    "    \n",
    "    Adding distortion might make the \"Hash\" be a bit more robust regarding uniqueness for some symetric objects (see issue with k_uni).\n",
    "    \"\"\"\n",
    "    \n",
    "    if ignore_dir:\n",
    "        distortion = torch.Tensor([[1, 1, 1],[1, 1, 1],[1, 1, 1]]);\n",
    "    else:\n",
    "        distortion = torch.Tensor([[1.01, 1.02, 1.03],[1.04, 1.05, 1.06],[1.07, 1.08, 1.09]]);\n",
    "    \n",
    "    return (kernel*distortion).view((1,1,3,3,1))\n",
    "    \n",
    "\n",
    "def k_uni(ignore_dir = True):\n",
    "    \"\"\"\n",
    "    Direction does not matter, e.g. \n",
    "    \n",
    "        xxxx               xxx\n",
    "         xxx   is equals   xxxx\n",
    "         \n",
    "    \"Hash\" might not be unique for some symetric objects, e.g.\n",
    "\n",
    "          x                      x\n",
    "         x    considered equals   x\n",
    "        xx                       xx\n",
    "    \n",
    "    \"\"\"\n",
    "    kernel = torch.Tensor([[1, 1, 1],\n",
    "                           [1, 1, 1],\n",
    "                           [1, 1, 1]])\n",
    "    \n",
    "    return k_gen(kernel, ignore_dir)\n",
    "\n",
    "\n",
    "def k_plus(ignore_dir = True):\n",
    "    \"\"\"\n",
    "    Same as k_uni, but doesn't consider diagonals as connection, e.g.\n",
    "    \n",
    "          xx\n",
    "          xx     k_uni: 1 object\n",
    "        xx       k_plus: 2 objects\n",
    "        xx     \n",
    "        \n",
    "    \"\"\"\n",
    "    kernel = torch.Tensor([[0, 1, 0],\n",
    "                           [1, 1, 1],\n",
    "                           [0, 1, 0]])\n",
    "    \n",
    "    return k_gen(kernel, ignore_dir)\n",
    "\n",
    "\n",
    "def k_x(ignore_dir = True):\n",
    "    \"\"\"\n",
    "    Same as k_uni, but only considers diagonals as connection, e.g.\n",
    "    \n",
    "          xx\n",
    "          xx     k_uni: 1 object\n",
    "        xx       k_plus: 2 objects\n",
    "        xx       k_x: 3 objects\n",
    "        \n",
    "    \"\"\"\n",
    "    kernel = torch.Tensor([[1, 0, 1],\n",
    "                           [0, 1, 0],\n",
    "                           [1, 0, 1]])\n",
    "    \n",
    "    return k_gen(kernel, ignore_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor([[1, 1, 1],[1, 1, 1],[1, 1, 1]]) * torch.Tensor([[1, 1, 1],[1, 1, 1],[1, 1, 1]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(      class_id    x    y  color  class_elem_cnt  class_elem_cnt_rank\n",
       " 0  212972576.0  3.0  0.0    7.0             4.0                  1.0\n",
       " 1  212972576.0  3.0  1.0    7.0             4.0                  1.0\n",
       " 2  212972576.0  3.0  2.0    7.0             4.0                  1.0\n",
       " 3  212972576.0  3.0  3.0    7.0             4.0                  1.0,\n",
       " tensor([[0., 0., 0., 1., 0., 0., 0.],\n",
       "         [0., 0., 0., 1., 0., 0., 0.],\n",
       "         [0., 0., 0., 1., 0., 0., 0.],\n",
       "         [0., 0., 0., 1., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0.]]),\n",
       "       class_id  class_elem_cnt  class_count  class_elem_cnt_rank\n",
       " 0  212972576.0               4            1                  1.0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ObjectDetail:\n",
    "    \n",
    "    \n",
    "    def __init__(self, colors, locs, shadow_locs, freq_per_color, freq_total, parent_objects, obj_classes):\n",
    "        self.colors = colors\n",
    "        self.locs = locs\n",
    "        self.shadow_locs = shadow_locs\n",
    "        self.freq_per_color = freq_per_color\n",
    "        self.freq_total = freq_total\n",
    "        self.parent_objects = parent_objects\n",
    "        self.obj_classes = obj_classes\n",
    "\n",
    "\n",
    "        \n",
    "class ClassDetail:\n",
    "    \n",
    "    \n",
    "    def __init__(self, colors, locs, shadow_locs, freq_per_color, freq_total, parent_objects, obj_classes):\n",
    "        self.colors = colors\n",
    "        self.locs = locs\n",
    "        self.shadow_locs = shadow_locs\n",
    "        self.freq_per_color = freq_per_color\n",
    "        self.freq_total = freq_total\n",
    "        self.parent_objects = parent_objects\n",
    "        self.obj_classes = obj_classes\n",
    "\n",
    "\n",
    "        \n",
    "class ObjectIndex:\n",
    "    \n",
    "    \n",
    "    SHADOW_CHANNEL = 10\n",
    "    \n",
    "    \n",
    "    def __init__(self, img, kernel=k_uni(), neighbours = 10, bg = None):\n",
    "    \n",
    "        self.img = img\n",
    "        \n",
    "        self.bg = bg\n",
    "        \n",
    "        self.kernel = kernel\n",
    "        \n",
    "        # convert to 11 channel (1 for each color + one for all non background colors) and apply one hot encoding\n",
    "        self.ohe = self.__ohe_ch(img, 11).unsqueeze(0).float()\n",
    "\n",
    "        # get non background color channels\n",
    "        self.non_bg_channels = list(set([i for i in range(10)])-set([bg]))\n",
    "\n",
    "        # add \"shadow\" channel including all ohe of non bg channels. \n",
    "        # This becomes the object-identifying channel while the other channels can be used \n",
    "        # to identify (color dependent) parts of an objects, e.g.\n",
    "        #\n",
    "        #            ##OX                         ##      O        X\n",
    "        #    Object   ##X  consists of the part  ##  and     and   X\n",
    "        #\n",
    "        self.ohe[:,:,:,:,self.SHADOW_CHANNEL] = self.ohe[:,:,:,:,self.non_bg_channels].sum(axis=4)\n",
    "\n",
    "        # normalization parameter\n",
    "        ndiv=kernel.sum()\n",
    "\n",
    "        obj_map = self.ohe\n",
    "        for i in range(neighbours):\n",
    "            # calculate \"hash\"-like values for the objects\n",
    "            obj_map = (F.conv3d(obj_map, kernel, padding=[1,1,0]) * self.ohe).div(ndiv) * (i+1)\n",
    "        obj_map = (obj_map*10000).round() # round to avoid fload precision issue while using as hash\n",
    "        \n",
    "        freq = {'freq_obj_col_'+str(i): Counter(obj_map[:,:,:,:,i].flatten().numpy()) for i in self.non_bg_channels}\n",
    "        freq['freq_obj_shadow']= Counter(obj_map[:,:,:,:,self.SHADOW_CHANNEL].flatten().numpy())\n",
    "        freq['freq_obj_all_col'] = Counter(obj_map[:,:,:,:, self.non_bg_channels].flatten().numpy())\n",
    "        # remove zeros (no object)\n",
    "        for c in freq:\n",
    "            del freq[c][0]\n",
    "\n",
    "        self.freq = freq\n",
    "        self.obj_map = obj_map\n",
    "       \n",
    "        ## cluster shadow objects to parent objects\n",
    "        self.obj_cluster, self.obj_class, self.class_count = self.__cluster_parent_objects(self.obj_map[:,:,:,:,-1].view(self.img.shape[0], \n",
    "                                                                                                       self.img.shape[1]), \n",
    "                                                                         self.kernel.view(3,3))\n",
    "        \n",
    "        # get some details per object\n",
    "        self.object_details = {} \n",
    "        for obj_id in torch.unique(obj_map):\n",
    "            colors = self.find_colors(obj_id)\n",
    "            locs = self.find_locs(obj_id)\n",
    "            shadow_locs = self.find_locs(obj_id, shadow_locs = True)\n",
    "            freq_per_color = self.find_color_freq(obj_id)\n",
    "            freq_total = locs.shape[0]\n",
    "            parent_objects = self.find_objects(locs, self.SHADOW_CHANNEL)\n",
    "            if isinstance(self.obj_class, pd.DataFrame):\n",
    "                obj_classes = self.obj_class['class_id'].unique()\n",
    "            else:\n",
    "                obj_classes = None\n",
    "            self.object_details[obj_id.item()] = ObjectDetail(colors, locs, shadow_locs, freq_per_color, freq_total, parent_objects, obj_classes)\n",
    "        \n",
    "        \n",
    "    def find_locs(self, obj_id, shadow_locs = False, locs_only = True):\n",
    "    \n",
    "        if shadow_locs:\n",
    "            search_channels = self.SHADOW_CHANNEL\n",
    "        else: \n",
    "            search_channels = self.non_bg_channels\n",
    "            \n",
    "        return self.__find_by_id(obj_id, search_channels, locs_only)\n",
    "    \n",
    "    \n",
    "    def find_colors(self, obj_id):\n",
    "        \n",
    "        return (self.obj_map[:,:,:,:,:-1] == obj_id).nonzero()[:,-1].unique().tolist()\n",
    "        \n",
    "   \n",
    "    def find_color_freq(self, obj_id):\n",
    "        \n",
    "        return Counter((self.obj_map[:,:,:,:,:-1] == obj_id).nonzero()[:,-1].flatten().numpy())\n",
    "        \n",
    "    \n",
    "    def find_objects(self, locs, search_channels):\n",
    "        \n",
    "        o = Tensor()\n",
    "        \n",
    "        for i, l in enumerate(locs):\n",
    "            o = torch.cat((o,self.obj_map[:,:,:,:,search_channels][:,:,l[0],l[1]]),-1)\n",
    "        \n",
    "        return o.unique()[o.unique()!=0.] # remove 0 from list\n",
    "    \n",
    "    \n",
    "    def __find_by_id(self, obj_id, search_channels, locs_only):\n",
    "        \n",
    "        locs = (self.obj_map[:,:,:,:,search_channels] == obj_id).nonzero()\n",
    "        \n",
    "        if locs_only:\n",
    "            locs = locs[:,2:4]\n",
    "        \n",
    "        return locs\n",
    "    \n",
    "        \n",
    "    def __ohe_ch(self, x, channels = 10):\n",
    "        \"\"\" Converts an np.array to n one hot encoded channels\"\"\"\n",
    "        x_shape = x.shape\n",
    "        x =  Tensor(x).flatten().long()\n",
    "        return torch.nn.functional.one_hot(x,channels).view(x_shape[0],x_shape[1],channels).unsqueeze(0)\n",
    " \n",
    "    \n",
    "    def __cluster_parent_objects(self, t, k):\n",
    "        z = torch.zeros(t.shape[0], t.shape[1])\n",
    "        z_class = None\n",
    "        class_attr = None\n",
    "        d_loc = {}\n",
    "        d_parent_id = {}\n",
    "        \n",
    "        max_parent_id = 0\n",
    "        for i in t.nonzero():\n",
    "            parent_id = None\n",
    "            i_key = str(i[0].item())+'_'+ str(i[1].item()) # \"/1\" => to float\n",
    "            for offset in k.nonzero()+Tensor([-1,-1]):\n",
    "                lu_loc = (i + offset).to(torch.int)\n",
    "                genkey = str(int(lu_loc[0].item()))+'_'+ str(int(lu_loc[1].item()))\n",
    "\n",
    "                # 1st it\n",
    "                if parent_id == None:\n",
    "                    parent = d_parent_id.get(genkey)\n",
    "\n",
    "                    if parent == None:\n",
    "                        max_parent_id += 1\n",
    "                        parent_id = max_parent_id\n",
    "                    else:\n",
    "                        parent_id = parent.get('id')\n",
    "\n",
    "                    z[i[0].item(), i[1].item()] = parent_id\n",
    "                    d_parent_id[i_key] = {'id': parent_id, 'child_val': t[i[0].item(), i[1].item()]}\n",
    "                    cur_locs = d_loc.get(parent_id)\n",
    "                    if cur_locs == None:\n",
    "                        d_loc[parent_id] = {'locs': [i_key], 'class_id': t[i[0].item(), i[1].item()]}\n",
    "                    else:\n",
    "                        d_loc[parent_id] = {'locs': cur_locs['locs'] + [i_key], 'class_id': cur_locs['class_id'] + t[i[0].item(), i[1].item()]}\n",
    "\n",
    "\n",
    "                # other it\n",
    "                elif genkey!=i_key:\n",
    "                    # lookup if loc has already been registered\n",
    "                    cur_parent = d_parent_id.get(genkey)\n",
    "                    if cur_parent != None:\n",
    "                        cur_parent_id = cur_parent.get('id')\n",
    "                        # merge parent_ids\n",
    "                        cur_locs = d_loc.get(cur_parent_id)\n",
    "                        for cl in cur_locs['locs']: # list of locs\n",
    "                            # set new parent_id\n",
    "                            d_parent_id[cl] = {'id': parent_id, 'child_val': t[i[0].item(), i[1].item()]}\n",
    "                            z[int(cl.split('_')[0]), int(cl.split('_')[1])] = parent_id\n",
    "\n",
    "                        if cur_parent_id != parent_id:\n",
    "                            temp_d_loc_entry = {'locs': d_loc.get(parent_id)['locs'] + cur_locs['locs'], 'class_id': d_loc.get(parent_id)['class_id'] + cur_locs['class_id'] }\n",
    "                            d_loc[parent_id] = temp_d_loc_entry\n",
    "                            del d_loc[cur_parent_id]\n",
    "                             #del d_val[cur_parent_id]\n",
    "        \n",
    "        for d in d_loc:\n",
    "            \n",
    "            class_id = d_loc.get(d)['class_id'].item()\n",
    "            class_elem_cnt = len(d_loc.get(d)['locs'])\n",
    "            \n",
    "            #count classes and class element\n",
    "            if not isinstance(class_attr, pd.DataFrame):\n",
    "                class_attr = pd.DataFrame({'class_id': [class_id], \n",
    "                            'class_elem_cnt': [class_elem_cnt]})\n",
    "            else:\n",
    "                class_attr = class_attr.append({'class_id': class_id, \n",
    "                            'class_elem_cnt': class_elem_cnt}, ignore_index=True)\n",
    "            \n",
    "            #locs\n",
    "            for l in d_loc.get(d)['locs']:\n",
    "                #z_class[int(l.split('_')[0]), int(l.split('_')[1])] = class_id\n",
    "                if not isinstance(z_class, pd.DataFrame):\n",
    "                    z_class = pd.DataFrame({'class_id': [class_id], \n",
    "                                'x':[int(l.split('_')[1])], \n",
    "                                'y':[int(l.split('_')[0])],\n",
    "                                'color': [self.img[int(l.split('_')[0]), int(l.split('_')[1])]],\n",
    "                                'class_elem_cnt': class_elem_cnt})\n",
    "                else:\n",
    "                    z_class = z_class.append({'class_id': class_id, \n",
    "                                'x':int(l.split('_')[1]), \n",
    "                                'y':int(l.split('_')[0]),\n",
    "                                'color': self.img[int(l.split('_')[0]), int(l.split('_')[1])],\n",
    "                                'class_elem_cnt': class_elem_cnt}, ignore_index=True)\n",
    "        \n",
    "        \n",
    "        if isinstance(class_attr, pd.DataFrame):\n",
    "            class_attr = class_attr.drop_duplicates()\n",
    "            class_attr['class_count'] = class_attr.groupby(['class_id'])['class_id'].transform('count')\n",
    "            class_attr['class_elem_cnt_rank'] = class_attr['class_elem_cnt'].rank(method = 'dense').drop_duplicates().reset_index(drop= True)\n",
    "        \n",
    "        if isinstance(z_class, pd.DataFrame):\n",
    "            z_class['class_elem_cnt_rank'] = z_class['class_elem_cnt'].rank(method = 'dense')\n",
    "        \n",
    "        return z, z_class, class_attr\n",
    "\n",
    "        \n",
    "### Test\n",
    "\n",
    "img = task_sample_arr('db3e9e38', test_train = 'train', in_out = 'input', idx = 0, path = training_path) #e8593010\n",
    "oi = ObjectIndex(img, kernel = k_plus(), bg = 0)\n",
    "\n",
    "#img, oi.freq, oi.obj_map[:,:,:,:,6], oi.find_locs(21332932, False), oi.find_locs(21332932), oi.find_colors(21332932), oi.object_details[21332932].colors, \n",
    "\n",
    "oi.obj_class, oi.obj_cluster, oi.class_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({219419620.0: 12, 3716.0: 4}) Counter({219419620.0: 16})\n",
      "Counter({3716.0: 12}) Counter({219419620.0: 12})\n",
      "Counter({346499420.0: 6, 324430750.0: 3, 415637300.0: 3, 194653250.0: 3, 3805073.0: 2, 21332932.0: 2, 30169322.0: 1}) Counter({346499420.0: 8, 324430750.0: 4, 415637300.0: 4, 194653250.0: 4})\n",
      "Counter({3805073.0: 6, 21332932.0: 6, 30169322.0: 3}) Counter({346499420.0: 6, 324430750.0: 3, 415637300.0: 3, 194653250.0: 3})\n"
     ]
    }
   ],
   "source": [
    "img = task_sample_arr('321b1fc6', test_train = 'train', in_out = 'input', idx = 0)\n",
    "oii0 = ObjectIndex(img, kernel = k_plus(), bg = 0)\n",
    "print(oii0.freq['freq_obj_all_col'], oii0.freq['freq_obj_shadow'])\n",
    "\n",
    "img = task_sample_arr('321b1fc6', test_train = 'train', in_out = 'output', idx = 0)\n",
    "oio0 = ObjectIndex(img, kernel = k_plus(), bg = 0)\n",
    "print(oio0.freq['freq_obj_all_col'], oio0.freq['freq_obj_shadow'])\n",
    "\n",
    "img = task_sample_arr('321b1fc6', test_train = 'train', in_out = 'input', idx = 1)\n",
    "oii1 = ObjectIndex(img, kernel = k_plus(), bg = 0)\n",
    "print(oii1.freq['freq_obj_all_col'], oii1.freq['freq_obj_shadow'])\n",
    "\n",
    "img = task_sample_arr('321b1fc6', test_train = 'train', in_out = 'output', idx = 1)\n",
    "oio1 = ObjectIndex(img, kernel = k_plus(), bg = 0)\n",
    "print(oio1.freq['freq_obj_all_col'], oio1.freq['freq_obj_shadow'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "same image size\n",
      "same shadow, different objects => some objects changed, but kept shadow (e.g. framing, filling, 50cb2852).\n",
      "removed objects: 0.\n",
      "added objects: 0.\n",
      "some colors changed: 16.\n",
      "some class_colors changed: 6.\n",
      "some class_elem_cnt changed: 6.\n",
      "some class_elem_cnt changed: 6.\n",
      "1 palettes changed.\n",
      "2 colors in use by image 1.\n"
     ]
    }
   ],
   "source": [
    "def reduce_color_map(color_map, key = 'class_id'):\n",
    "    # make sure mapping is unique\n",
    "    color_map.drop_duplicates(inplace = True)\n",
    "    color_map['cnt_by_from'] = color_map.groupby([key, 'color_from'])[key].transform('count')\n",
    "    return color_map[color_map.cnt_by_from == 1][[key, 'color_from', 'color_to']]\n",
    "\n",
    "\n",
    "def bg(img):\n",
    "\n",
    "    all_colors = [i for lst in img for i in lst.reshape(1,-1).tolist()]\n",
    "    bgcolor = stats.mode(all_colors,axis=None)[0]\n",
    "\n",
    "    return bgcolor[0]\n",
    "\n",
    "\n",
    "def common_bgcolor(img1, img2):\n",
    "    \"\"\"\n",
    "    None if different background color.\n",
    "    \"\"\"\n",
    "\n",
    "    bgcolor = None\n",
    "\n",
    "    bg1 = bg(img1)\n",
    "    bg2 = bg(img2)\n",
    "\n",
    "    if bg1 == bg2:\n",
    "        bgcolor = bg1\n",
    "\n",
    "    return bgcolor\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class IdxComperator():\n",
    "    \n",
    "    SHADOW_CHANNEL = 10\n",
    "    \n",
    "    def __init__(self, object_index_1, object_index_2):\n",
    "        \n",
    "        self.object_index_1 = object_index_1\n",
    "        self.object_index_2 = object_index_2\n",
    "        \n",
    "    \n",
    "    ########################\n",
    "    ### Image in general ###\n",
    "    ########################\n",
    "    \n",
    "    \n",
    "    def scale_factor(self):\n",
    "        \n",
    "        return (self.object_index_1.img.shape[0] / self.object_index_2.img.shape[0], \n",
    "                self.object_index_1.img.shape[1] / self.object_index_2.img.shape[1])\n",
    "        \n",
    "    \n",
    "    ########################\n",
    "    ###  Shadow related  ###\n",
    "    ########################\n",
    "\n",
    "    \n",
    "    def same_shadow(self):\n",
    "        \n",
    "        return (self.object_index_1.obj_map[:,:,:,:, self.SHADOW_CHANNEL] == self.object_index_2.obj_map[:,:,:,:, self.SHADOW_CHANNEL]).min().item()\n",
    "    \n",
    "    \n",
    "    ########################\n",
    "    ###  Object related  ###\n",
    "    ########################\n",
    "\n",
    "    \n",
    "    def diff_num_obj_per_channel(self):\n",
    "    \n",
    "        n = []\n",
    "        for cf in self.object_index_1.freq:\n",
    "            n.append(sum(self.object_index_1.freq[cf].values()) - sum(self.object_index_2.freq[cf].values()))\n",
    "    \n",
    "        return n\n",
    "    \n",
    "    \n",
    "    def removed_objects(self):\n",
    "        \n",
    "        objs1 = self.object_index_1.object_details.keys()\n",
    "        objs2 = self.object_index_2.object_details.keys()\n",
    "        \n",
    "        return list(set(objs1) - set(objs2))\n",
    "    \n",
    "    \n",
    "    def added_objects(self):\n",
    "    \n",
    "        objs1 = self.object_index_1.object_details.keys()\n",
    "        objs2 = self.object_index_2.object_details.keys()\n",
    "        \n",
    "        return list(set(objs2) - set(objs1))\n",
    "    \n",
    "    \n",
    "    # map for obj when color changed\n",
    "    def color_map(self):\n",
    "        \n",
    "        color_map = {}\n",
    "        \n",
    "        ods1 = self.object_index_1.object_details\n",
    "        ods2 = self.object_index_2.object_details\n",
    "        \n",
    "        for o in ods1:\n",
    "            details1 = ods1.get(o)\n",
    "            if details1 == None:\n",
    "                    continue\n",
    "            colors1 = details1.colors\n",
    "            details2 = ods2.get(o)\n",
    "            if details2 == None:\n",
    "                    continue\n",
    "            colors2 = details2.colors\n",
    "\n",
    "            if list(colors1) != list(colors2) and list(colors2) != []:\n",
    "                color_map[o] = {'from': colors1, 'to': colors2}\n",
    "                \n",
    "        return color_map\n",
    "    \n",
    "    \n",
    "    # map for classes when color changed\n",
    "    def class_color_map(self, key = 'class_id'):\n",
    "        \n",
    "        color_map = None\n",
    "        \n",
    "        if isinstance(self.object_index_1.obj_class, pd.DataFrame) and isinstance(self.object_index_2.obj_class, pd.DataFrame):\n",
    "            oc1 = self.object_index_1.obj_class[[key, 'color']].drop_duplicates()\n",
    "            oc2 = self.object_index_2.obj_class[[key, 'color']].drop_duplicates()\n",
    "            \n",
    "            color_map = oc1.merge(oc2.set_index(key), 'inner', on = [key], suffixes = ('_from', '_to')).drop_duplicates().reset_index(drop = True)\n",
    "            if isinstance(color_map, pd.DataFrame):\n",
    "                color_map = reduce_color_map(color_map, key = key) \n",
    "        \n",
    "        return color_map\n",
    "    \n",
    "    \n",
    "    # map for classes when they have same number of elements rank and color changed\n",
    "    def class_elem_cnt_rank_color_map(self):\n",
    "        \n",
    "        return self.class_color_map(key = 'class_elem_cnt_rank')\n",
    "        \n",
    "    \n",
    "    # map for classes when they have same number of elements and color changed\n",
    "    def class_elem_cnt_color_map(self):\n",
    "        \n",
    "       # color_map = None\n",
    "       # \n",
    "       # if isinstance(self.object_index_1.obj_class, pd.DataFrame) and isinstance(self.object_index_2.obj_class, pd.DataFrame):\n",
    "       #     oc1 = self.object_index_1.obj_class[['class_id', 'color']].merge(\n",
    "       #                 self.object_index_1.class_count[['class_id', 'class_elem_cnt']].set_index('class_id'),\n",
    "       #                 'inner', on = ['class_id']).drop_duplicates().reset_index(drop = True)[['class_elem_cnt', 'color']]\n",
    "       #     oc2 = self.object_index_2.obj_class[['class_id', 'color']].merge(\n",
    "       #                 self.object_index_2.class_count[['class_id', 'class_elem_cnt']].set_index('class_id'),\n",
    "       #                 'inner', on = ['class_id']).drop_duplicates().reset_index(drop = True)[['class_elem_cnt', 'color']]\n",
    "       #     \n",
    "       #     color_map = oc1.merge(oc2.set_index('class_elem_cnt'), 'left', on = ['class_elem_cnt'], suffixes = ('_from', '_to')).drop_duplicates().reset_index(drop = True)\n",
    "       #     color_map = reduce_color_map(color_map, key = 'class_elem_cnt') \n",
    "        \n",
    "        return self.class_color_map(key = 'class_elem_cnt')\n",
    "    \n",
    "    \n",
    "    # check if whole color channel has switched  \n",
    "    def palette_map(self):\n",
    "        \n",
    "        palette_map = {} # from: to\n",
    "        \n",
    "        om1 = self.object_index_1.ohe\n",
    "        om2 = self.object_index_2.ohe\n",
    "        \n",
    "        for i in range(10):\n",
    "            for j in range(10):\n",
    "                if (om1[:,:,:,:,i] - om2[:,:,:,:,j]).max() < 1 and (om1[:,:,:,:,i]).max() == 1: #i != j and \n",
    "                    palette_map[i] = j\n",
    "    \n",
    "        return palette_map\n",
    "    \n",
    "    \n",
    "    def color_in_use(self):\n",
    "        \n",
    "        c = []\n",
    "        \n",
    "        om1 = self.object_index_1.ohe\n",
    "        \n",
    "        for i in range(10):\n",
    "            if (om1[:,:,:,:,i]).max() == 1:\n",
    "                c = c + [i]\n",
    "        \n",
    "        return c\n",
    "    \n",
    "    \n",
    "    # map for obj when coordinates changed\n",
    "    def location_map(self):\n",
    "        \n",
    "        loc_map = {}\n",
    "        \n",
    "        ods1 = self.object_index_1.object_details\n",
    "        ods2 = self.object_index_2.object_details\n",
    "        for o in ods1:\n",
    "            details1 = ods1.get(o)\n",
    "            if details1 == None:\n",
    "                    continue\n",
    "            locs1 = details1.locs.tolist()\n",
    "            details2 = ods2.get(o)\n",
    "            if details2 == None:\n",
    "                    continue\n",
    "            locs2 = details2.locs.tolist()\n",
    "\n",
    "            if locs1 != locs2 and locs2 != []:\n",
    "                loc_map[o] = {'from': locs1, 'to': locs2}\n",
    "                \n",
    "        return loc_map\n",
    "    \n",
    "    \n",
    "    # map old to new object depending of coordinates\n",
    "    def object_map(self, same_color, ignore_bg = False):\n",
    "        \n",
    "        if ignore_bg:\n",
    "            ch1 = self.object_index_1.non_bg_channels\n",
    "            ch2 = self.object_index_2.non_bg_channels\n",
    "        else:\n",
    "            ch1 = list(range(10))\n",
    "            ch2 = list(range(10))\n",
    "        \n",
    "        bg1 = self.object_index_1.bg\n",
    "        bg2 = self.object_index_2.bg\n",
    "        \n",
    "        oi1 = self.object_index_1.obj_map[:,:,:,:,ch1]\n",
    "        oi1s = oi1.view(oi1.shape[2:]).sum(axis=-1)\n",
    "        oi2 = self.object_index_2.obj_map[:,:,:,:,ch2]\n",
    "        oi2s = oi2.view(oi2.shape[2:]).sum(axis=-1)\n",
    "        \n",
    "        diff_mask = oi1s != oi2s\n",
    "        \n",
    "        o_old = oi1s[diff_mask]\n",
    "        o_new = oi2s[diff_mask]\n",
    "        c_old = self.object_index_1.img[diff_mask]\n",
    "        c_new = self.object_index_2.img[diff_mask]\n",
    "        loc = diff_mask.nonzero()\n",
    "        \n",
    "        return [{'obj_old': old.item(), \n",
    "                 'obj_new': o_new[i].item(), \n",
    "                 'color_old': c_old[i], \n",
    "                 'color_new': c_new[i],\n",
    "                 'loc': loc[i],\n",
    "                 'cluster': self.object_index_1.obj_cluster[loc[i][0],loc[i][1]].item()} \n",
    "                for i, old in enumerate(o_old) if ((same_color and c_old[i] == c_new[i]) or \n",
    "                                                    (not same_color and c_old[i] != c_new[i])) and\n",
    "                                                    (not ignore_bg or \n",
    "                                                    (ignore_bg and c_old[i] != bg1 and c_new[i] != bg2))]\n",
    "\n",
    "    \n",
    "    def removed_classes(self):\n",
    "        ncl1 = self.object_index_1.class_count\n",
    "        ncl2 = self.object_index_2.class_count\n",
    "        \n",
    "       \n",
    "        ncl = ncl1.merge(ncl2, 'left', on='class_id')\n",
    "        ncl['removed_classes'] = ncl.class_count_x - ncl.class_count_y\n",
    "        ncl = ncl[ncl.removed_classes > 0].drop(['class_count_x', 'class_count_y'],axis=1)\n",
    "        \n",
    "        return ncl\n",
    "    \n",
    "    \n",
    "    def added_classes(self):\n",
    "        ncl1 = self.object_index_1.class_count\n",
    "        ncl2 = self.object_index_2.class_count\n",
    "        \n",
    "        ncl = ncl2.merge(ncl1, 'left', on='class_id')\n",
    "        ncl['added_classes'] = ncl.class_count_x - ncl.class_count_y\n",
    "        ncl = ncl[ncl.added_classes > 0].drop(['class_count_x', 'class_count_y'],axis=1)\n",
    "        \n",
    "        return ncl\n",
    "    \n",
    "    \n",
    "   # def color_of_cluster_changed(self):\n",
    "            \n",
    "    \n",
    "    def interpreter(self):\n",
    "    \n",
    "        msg = []\n",
    "    \n",
    "        if self.scale_factor() != (1,1):\n",
    "            msg.append('different image size => split image and compare parts separetly')\n",
    "        else:\n",
    "            msg.append('same image size')\n",
    "            \n",
    "            if self.same_shadow() and min(self.diff_num_obj_per_channel()) == 0:\n",
    "                msg.append('same shadow, same objects => some objects changed color')\n",
    "\n",
    "            if self.same_shadow() and min(self.diff_num_obj_per_channel()) != 0:\n",
    "                msg.append('same shadow, different objects => '+\n",
    "                           'some objects changed, but kept shadow (e.g. framing, filling, 50cb2852).')\n",
    "        \n",
    "        msg.append(f'removed objects: {len(self.removed_objects())}.')\n",
    "        \n",
    "        msg.append(f'added objects: {len(self.added_objects())}.')\n",
    "        \n",
    "        if len(self.removed_objects()) != len(self.added_objects()):\n",
    "            msg.append(f'diff between removed objects and added objects happens if removed objects stay part of the shadow, hence only color changed.')\n",
    "        \n",
    "        if len(self.color_map()) > 0:\n",
    "            msg.append(f'some colors changed: {len(self.color_map())}.')\n",
    "        \n",
    "        if len(self.class_color_map()) > 0:\n",
    "            msg.append(f'some class_colors changed: {len(self.class_color_map())}.')\n",
    "        \n",
    "        if len(self.class_elem_cnt_color_map()) > 0:\n",
    "            msg.append(f'some class_elem_cnt changed: {len(self.class_elem_cnt_color_map())}.')\n",
    "        \n",
    "        if len(self.class_elem_cnt_rank_color_map()) > 0:\n",
    "            msg.append(f'some class_elem_cnt changed: {len(self.class_elem_cnt_rank_color_map())}.')\n",
    "        \n",
    "        if self.scale_factor() == (1,1) and len(self.palette_map()) > 0:\n",
    "            msg.append(f'{len(self.palette_map())} palettes changed.')\n",
    "        \n",
    "        if len(self.color_in_use()) > 0:\n",
    "            msg.append(f'{len(self.color_in_use())} colors in use by image 1.')\n",
    "        \n",
    "        if len(self.location_map()) > 0:\n",
    "            msg.append(f'some object coordinates changed: {len(self.location_map())}.')\n",
    "            \n",
    "        if self.scale_factor() == (1,1):\n",
    "        \n",
    "            if len(self.object_map(same_color = True, ignore_bg = False)) > 0:\n",
    "                msg.append(f'objects changed but not the color (by loc, incl. backgroud): {len(self.object_map(same_color = True))}.')\n",
    "\n",
    "            if len(self.object_map(same_color = False, ignore_bg = False)) > 0:\n",
    "                msg.append(f'objects and color changed (by loc, incl. backgroud): {len(self.object_map(same_color = False))}.')\n",
    "\n",
    "            if len(self.object_map(same_color = True, ignore_bg = True)) > 0:\n",
    "                msg.append(f'objects changed but not the color (by loc, ignoring backgroud): ' +\n",
    "                           f'{len(self.object_map(same_color = True, ignore_bg = True))}.')\n",
    "\n",
    "            if len(self.object_map(same_color = False, ignore_bg = True)) > 0:\n",
    "                msg.append(f'objects and color changed (by loc, ignoring backgroud): ' +\n",
    "                           f'{len(self.object_map(same_color = False, ignore_bg = True))}.')\n",
    "                    \n",
    "        if (len(self.removed_classes())) > 0:\n",
    "            msg.append(f'Objects of {len(self.removed_classes())} classes have been removed.')\n",
    "        \n",
    "        if (len(self.added_classes())) > 0:\n",
    "            msg.append(f'Objects of {len(self.added_classes())} classes have been add.')\n",
    "        \n",
    "        return msg\n",
    "    \n",
    "\n",
    "## Test\n",
    "imgi0 = task_sample_arr('ae58858e', test_train = 'train', in_out = 'input', idx = 1, path=evaluation_path)\n",
    "oii0 = ObjectIndex(imgi0, kernel = k_plus(), bg = 0)\n",
    "\n",
    "imgo0 = task_sample_arr('ae58858e', test_train = 'train', in_out = 'output', idx = 1, path=evaluation_path)\n",
    "oio0 = ObjectIndex(imgo0, kernel = k_plus(), bg = 0)\n",
    "\n",
    "## Rules: Frame keeps color\n",
    "ic0 = IdxComperator(oii0, oio0)\n",
    "\n",
    "imgi1 = task_sample_arr('e8593010', test_train = 'train', in_out = 'input', idx = 1)\n",
    "oii1 = ObjectIndex(imgi1, kernel = k_plus(), bg = 5)\n",
    "\n",
    "imgo1 = task_sample_arr('e8593010', test_train = 'train', in_out = 'output', idx = 1)\n",
    "oio1 = ObjectIndex(imgo1, kernel = k_plus(), bg = 5)\n",
    "\n",
    "ic1 = IdxComperator(oii1, oio1)\n",
    "\n",
    "imgo0,ic0.same_shadow(), ic1.same_shadow(), oii0.freq, oio0.freq, ic0.diff_num_obj_per_channel(),\n",
    "\n",
    "for m in ic0.interpreter():\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_class_color_map(common_class_color_map, ic, key = 'class_id'):\n",
    "    iccm = ic.class_color_map(key)\n",
    "    if isinstance(iccm, pd.DataFrame):\n",
    "        if not isinstance(common_class_color_map, pd.DataFrame) :\n",
    "            common_class_color_map = iccm\n",
    "        else:\n",
    "            common_class_color_map = common_class_color_map.append(iccm).reset_index(drop=True)\n",
    "\n",
    "        common_class_color_map = reduce_color_map(common_class_color_map, key).reset_index(drop=True)\n",
    "    \n",
    "    return common_class_color_map\n",
    "   \n",
    "\n",
    "\n",
    "class task_comperator():\n",
    "    \n",
    "    def __init__(self, idx_comperator_list):\n",
    "        \n",
    "        self.in_out_same_size = True\n",
    "        self.max_removed_objects = 0\n",
    "        self.max_added_objects = 0\n",
    "        self.common_palette_map = {}\n",
    "        self.common_class_color_map = None\n",
    "        self.common_class_elem_cnt_color_map = None\n",
    "        self.common_scale_factor = None\n",
    "        self.common_class_elem_cnt_rank_color_map = None\n",
    "        \n",
    "        for i, ic in enumerate(idx_comperator_list):\n",
    "            self.in_out_same_size = self.in_out_same_size and ic.scale_factor() == (1,1)\n",
    "            self.max_removed_objects = max(self.max_removed_objects, len(ic.removed_objects()))\n",
    "            self.max_added_objects = max(self.max_added_objects, len(ic.added_objects()))\n",
    "            \n",
    "            for j in range(10):\n",
    "                if self.common_palette_map != None and self.in_out_same_size:\n",
    "                    # check if there is a valid color map\n",
    "                    if j in ic.color_in_use():\n",
    "                        ic_pmj = ic.palette_map().get(j)\n",
    "                        if ic_pmj != None:\n",
    "                            if self.common_palette_map.get(j) == None:\n",
    "                                self.common_palette_map[j] = ic_pmj\n",
    "                            elif ic_pmj != self.common_palette_map.get(j):\n",
    "                                self.common_palette_map = None  \n",
    "                        else:\n",
    "                            self.common_palette_map = None\n",
    "            \n",
    "            #iccm = ic.class_color_map()\n",
    "            #if isinstance(iccm, pd.DataFrame):\n",
    "            #    for j in iccm:\n",
    "            #        if not isinstance(self.common_class_color_map, pd.DataFrame) :\n",
    "            #            self.common_class_color_map = iccm\n",
    "            #        else:\n",
    "            #            self.common_class_color_map.append(ic.class_color_map())\n",
    "            #    self.common_class_color_map = reduce_color_map(self.common_class_color_map)                        \n",
    "            self.common_class_color_map = merge_class_color_map(self.common_class_color_map, ic, 'class_id')\n",
    "            \n",
    "            #icecm = ic.class_elem_cnt_color_map()\n",
    "            #if isinstance(icecm, pd.DataFrame):\n",
    "            #    for j in icecm:\n",
    "            #        if not isinstance(self.common_class_elem_cnt_color_map, pd.DataFrame) :\n",
    "            #            self.common_class_elem_cnt_color_map = icecm\n",
    "            #        else:\n",
    "            #            self.common_class_elem_cnt_color_map.append(ic.class_elem_cnt_color_map())\n",
    "            #    self.common_class_elem_cnt_color_map = reduce_color_map(self.common_class_elem_cnt_color_map, key = 'class_elem_cnt')                        \n",
    "            self.common_class_elem_cnt_color_map = merge_class_color_map(self.common_class_elem_cnt_color_map, ic, 'class_elem_cnt')\n",
    "            \n",
    "            self.common_class_elem_cnt_rank_color_map = merge_class_color_map(self.common_class_elem_cnt_rank_color_map, ic, 'class_elem_cnt_rank')\n",
    "               \n",
    "            if self.common_scale_factor == None:\n",
    "                self.common_scale_factor = ic.scale_factor()\n",
    "            elif self.common_scale_factor != ic.scale_factor():\n",
    "                self.common_scale_factor = ()\n",
    "     \n",
    "    \n",
    "    def interpreter(self):\n",
    "        msg = []\n",
    "        if self.in_out_same_size:\n",
    "            msg.append(f'input and output have always the same size')\n",
    "        elif len(self.common_scale_factor) > 0:\n",
    "            msg.append(f'Common in to out size scale factor of {self.common_scale_factor}.')\n",
    "        \n",
    "        msg.append(f'Max removed objects: {self.max_removed_objects}')\n",
    "        \n",
    "        msg.append(f'Max added objects: {self.max_added_objects}')\n",
    "        \n",
    "        if self.common_palette_map != None:\n",
    "            msg.append(f'Common palette map for {len(self.common_palette_map)} colors.')\n",
    "        \n",
    "        if len(self.common_class_color_map) > 0:\n",
    "            msg.append(f'Common class color map for {len(self.common_class_color_map)} colors.')\n",
    "        \n",
    "        if len(self.common_class_elem_cnt_color_map) > 0:\n",
    "            msg.append(f'Common class elem cnt color map for {len(self.common_class_elem_cnt_color_map)} colors.')\n",
    "        \n",
    "        if len(self.common_class_elem_cnt_rank_color_map) > 0:\n",
    "            msg.append(f'Common class elem cnt rank color map for {len(self.common_class_elem_cnt_rank_color_map)} colors.')\n",
    "        \n",
    "        return msg\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Rule\n",
    "class RuleDecoder:\n",
    "    \n",
    "    \n",
    "    def __init__(self, task_comperator):\n",
    "        \n",
    "        self.tc = task_comperator\n",
    "    \n",
    "    \n",
    "    def predict(self, img, rules=[], kernel = k_plus(), bg = 0):\n",
    "        \n",
    "        object_index = ObjectIndex(img, kernel = kernel, bg = bg)\n",
    "        \n",
    "        target = None\n",
    "        \n",
    "        '''if self.tc.in_out_same_size == True:\n",
    "            \n",
    "            # Rule 1: only Palette changed\n",
    "            if (self.tc.common_palette_map != None and \n",
    "                self.tc.max_removed_objects == 0 and\n",
    "                self.tc.max_added_objects == 0):\n",
    "                target = np.copy(img)\n",
    "                target = self.change_palette(target, self.tc.common_palette_map)\n",
    "                \n",
    "            # Rule 2a: class_elem_cnt_rank_color_map\n",
    "            elif len(self.tc.common_class_elem_cnt_rank_color_map) > 0:\n",
    "\n",
    "                target = np.copy(img)\n",
    "                target = self.change_class_color(target, object_index, self.tc.common_class_elem_cnt_rank_color_map, key='class_elem_cnt_rank')\n",
    "                return target\n",
    "            # Rule 2: class_elem_cnt_color_map\n",
    "            elif len(self.tc.common_class_elem_cnt_color_map) > 0:\n",
    "\n",
    "                target = np.copy(img)\n",
    "                target = self.change_class_color(target, object_index, self.tc.common_class_elem_cnt_color_map, key='class_elem_cnt')\n",
    "            \n",
    "            # Rule 3: class_color_map\n",
    "            elif (len(self.tc.common_class_color_map) > 0 and \n",
    "                self.tc.max_removed_objects == 0 and\n",
    "                self.tc.max_added_objects == 0):\n",
    "\n",
    "                target = np.copy(img)\n",
    "                target = self.change_class_color(target, object_index, self.tc.common_class_color_map)\n",
    "        '''\n",
    "        \n",
    "        for r in rules:\n",
    "            target = r(self.tc, img, object_index)\n",
    "        \n",
    "        return target\n",
    "    \n",
    "    \n",
    "    def r_palette_change(tc, img, object_index):\n",
    "        target = None\n",
    "        if (tc.in_out_same_size == True and \n",
    "            tc.common_palette_map != None and \n",
    "            tc.max_removed_objects == 0 and\n",
    "            tc.max_added_objects == 0):\n",
    "            \n",
    "            target = np.copy(img)\n",
    "            target = RuleDecoder.change_palette(target, tc.common_palette_map)\n",
    "        return target        \n",
    "        \n",
    "    \n",
    "    def r_cm_by_class_elem_cnt_rank(tc, img, object_index):\n",
    "        target = None\n",
    "        if (tc.in_out_same_size == True and \n",
    "            isinstance(tc.common_class_elem_cnt_rank_color_map, pd.DataFrame)):\n",
    "            \n",
    "            target = np.copy(img)\n",
    "            target = RuleDecoder.change_class_color(target, object_index, tc.common_class_elem_cnt_rank_color_map, key='class_elem_cnt_rank')\n",
    "        return target\n",
    "    \n",
    "    \n",
    "    def r_cm_by_class_elem_cnt(tc, img, object_index):\n",
    "        target = None\n",
    "        if (tc.in_out_same_size == True and \n",
    "            isinstance(tc.common_class_elem_cnt_color_map, pd.DataFrame)):\n",
    "\n",
    "            target = np.copy(img)\n",
    "            target = RuleDecoder.change_class_color(target, object_index, tc.common_class_elem_cnt_color_map, key='class_elem_cnt')\n",
    "        return target\n",
    "    \n",
    "    \n",
    "    def r_cm_class_id(tc, img, object_index):\n",
    "        target = None\n",
    "        if (tc.in_out_same_size == True and \n",
    "            isinstance(tc.common_class_color_map, pd.DataFrame) and \n",
    "            tc.max_removed_objects == 0 and\n",
    "            tc.max_added_objects == 0):\n",
    "            \n",
    "            target = np.copy(img)\n",
    "            target = RuleDecoder.change_class_color(target, object_index, tc.common_class_color_map)\n",
    "        return target    \n",
    "    \n",
    "    \n",
    "    #def scale(self, scale_factor, bg):\n",
    "        \n",
    "    #    self.trg = np.ones(self.src.shape * scale_factor) * bg\n",
    "    \n",
    "    \n",
    "    #def fill_bg(self, bg):\n",
    "     #   \n",
    "     #   self.trg = obj_map[:,:,:,:,bg]\n",
    "    \n",
    "    \n",
    "    #def cut_img(self, scale_factor, bg):\n",
    "     #   None\n",
    "        \n",
    "    \n",
    "    def change_palette(img, palette_map):\n",
    "        for p in palette_map:\n",
    "            img[img == p] = palette_map.get(p) + 50 # + 50 => avoid undo painting\n",
    "            \n",
    "        return img - 50\n",
    "        \n",
    "    \n",
    "    def change_class_color(img, object_index, class_color_map, key = 'class_id'):\n",
    "        cmap = class_color_map.merge(object_index.obj_class.set_index(key), 'inner', on = [key])\n",
    "        for i, row in cmap.iterrows():\n",
    "            if img[int(row.y), int(row.x)] == row.color_from:\n",
    "                img[int(row.y), int(row.x)] = row.color_to\n",
    "            \n",
    "        return img\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Train0 ###\n",
      "\n",
      "same image size\n",
      "same shadow, different objects => some objects changed, but kept shadow (e.g. framing, filling, 50cb2852).\n",
      "removed objects: 0.\n",
      "added objects: 0.\n",
      "some colors changed: 9.\n",
      "some class_colors changed: 6.\n",
      "some class_elem_cnt changed: 5.\n",
      "some class_elem_cnt changed: 5.\n",
      "1 palettes changed.\n",
      "2 colors in use by image 1.\n",
      "\n",
      "### Train1 ###\n",
      "\n",
      "same image size\n",
      "same shadow, different objects => some objects changed, but kept shadow (e.g. framing, filling, 50cb2852).\n",
      "removed objects: 0.\n",
      "added objects: 0.\n",
      "some colors changed: 16.\n",
      "some class_colors changed: 6.\n",
      "some class_elem_cnt changed: 6.\n",
      "some class_elem_cnt changed: 6.\n",
      "1 palettes changed.\n",
      "2 colors in use by image 1.\n",
      "\n",
      "### Train2 ###\n",
      "\n",
      "same image size\n",
      "same shadow, different objects => some objects changed, but kept shadow (e.g. framing, filling, 50cb2852).\n",
      "removed objects: 0.\n",
      "added objects: 0.\n",
      "some colors changed: 3.\n",
      "some class_colors changed: 4.\n",
      "some class_elem_cnt changed: 3.\n",
      "some class_elem_cnt changed: 3.\n",
      "1 palettes changed.\n",
      "2 colors in use by image 1.\n",
      "\n",
      "### All tasks ###\n",
      "\n",
      "input and output have always the same size\n",
      "Max removed objects: 0\n",
      "Max added objects: 0\n",
      "Common class color map for 10 colors.\n",
      "Common class elem cnt color map for 8 colors.\n",
      "Common class elem cnt rank color map for 5 colors.\n"
     ]
    }
   ],
   "source": [
    "taskname = 'ae58858e' # 'b1948b0a' #'4258a5f9' #'6f8cd79b' #'08ed6ac7' #'007bbfb7' '6e82a1ae' \n",
    "\n",
    "ic_list=[]\n",
    "for i in range(3):\n",
    "    imgi1 = task_sample_arr(taskname, test_train = 'train', in_out = 'input', idx = i, path=evaluation_path)\n",
    "    oii1 = ObjectIndex(imgi1, kernel = k_plus(), bg = 0)\n",
    "\n",
    "    imgo1 = task_sample_arr(taskname, test_train = 'train', in_out = 'output', idx = i, path=evaluation_path)\n",
    "    oio1 = ObjectIndex(imgo1, kernel = k_plus(), bg = 0)\n",
    "    \n",
    "    ic = IdxComperator(oii1, oio1)\n",
    "    ic_list.append(ic)\n",
    "    \n",
    "    print(f'\\n### Train{i} ###\\n')\n",
    "    \n",
    "    for m in ic.interpreter():\n",
    "        print(m)\n",
    "    \n",
    "\n",
    "print(f'\\n### All tasks ###\\n')\n",
    "tc = task_comperator(ic_list)\n",
    "\n",
    "for m in tc.interpreter():\n",
    "    print(m)\n",
    "#tc.common_class_elem_cnt_color_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0 0]\n",
      " [2 2 0 0 0 2 2 0]\n",
      " [0 2 2 0 0 2 2 0]\n",
      " [0 0 0 0 0 0 2 2]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 2 2 2 0 0 0 0]\n",
      " [0 0 0 0 0 2 0 0]\n",
      " [0 0 2 2 0 0 0 0]\n",
      " [2 0 2 2 0 0 2 2]\n",
      " [2 0 0 0 0 0 0 0]] \n",
      "==>\n",
      " [[0 0 0 0 0 0 0 0]\n",
      " [6 6 0 0 0 6 6 0]\n",
      " [0 6 6 0 0 6 6 0]\n",
      " [0 0 0 0 0 0 6 6]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 2 2 2 0 0 0 0]\n",
      " [0 0 0 0 0 2 0 0]\n",
      " [0 0 6 6 0 0 0 0]\n",
      " [2 0 6 6 0 0 2 2]\n",
      " [2 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "imgt0 = task_sample_arr(taskname, test_train = 'train', in_out = 'input', idx = 0, path=evaluation_path)\n",
    "\n",
    "r = RuleDecoder(tc)\n",
    "\n",
    "print(imgt0, '\\n==>\\n', r.predict(imgt0,[RuleDecoder.r_cm_by_class_elem_cnt_rank], kernel = k_plus(), bg = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From https://www.kaggle.com/inversion/abstraction-and-reasoning-starter-notebook\n",
    "def flattener(pred):\n",
    "    str_pred = str([row for row in pred])\n",
    "    str_pred = str_pred.replace(', ', '')\n",
    "    str_pred = str_pred.replace('[[', '|')\n",
    "    str_pred = str_pred.replace('][', '|')\n",
    "    str_pred = str_pred.replace(']]', '|')\n",
    "    return str_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Describe Train0 ###\n",
      "\n",
      "same image size\n",
      "removed objects: 20.\n",
      "added objects: 27.\n",
      "diff between removed objects and added objects happens if removed objects stay part of the shadow, hence only color changed.\n",
      "1 palettes changed.\n",
      "2 colors in use by image 1.\n",
      "some object coordinates changed: 1.\n",
      "objects changed but not the color (by loc, incl. backgroud): 19.\n",
      "objects and color changed (by loc, incl. backgroud): 12.\n",
      "\n",
      "### Describe Train1 ###\n",
      "\n",
      "same image size\n",
      "removed objects: 51.\n",
      "added objects: 63.\n",
      "diff between removed objects and added objects happens if removed objects stay part of the shadow, hence only color changed.\n",
      "1 palettes changed.\n",
      "2 colors in use by image 1.\n",
      "some object coordinates changed: 1.\n",
      "objects changed but not the color (by loc, incl. backgroud): 34.\n",
      "objects and color changed (by loc, incl. backgroud): 17.\n",
      "\n",
      "### Describe all tasks ###\n",
      "\n",
      "input and output have always the same size\n",
      "Max removed objects: 51\n",
      "Max added objects: 63\n",
      "\n",
      "### Eval rule on train:\n",
      "<function RuleDecoder.r_cm_by_class_elem_cnt_rank at 0x7fe32cca9048>\n",
      "no matching rule\n",
      "\n",
      "### Eval rule on train:\n",
      "<function RuleDecoder.r_cm_by_class_elem_cnt at 0x7fe32cca90d0>\n",
      "no matching rule\n",
      "\n",
      "### Eval rule on train:\n",
      "<function RuleDecoder.r_cm_class_id at 0x7fe32cca9158>\n",
      "no matching rule\n",
      "\n",
      "### Eval rule on train:\n",
      "<function RuleDecoder.r_palette_change at 0x7fe3597f6840>\n",
      "no matching rule\n",
      "no rules available for task db3e9e38\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predTask(taskname, path = training_path, explain = False, is_training = False):\n",
    "    \n",
    "    task = load_task(taskname, path = path)\n",
    "    \n",
    "    ic_list=[]\n",
    "\n",
    "    for i in range(len(task['train'])):\n",
    "        \n",
    "        img_in = np.array(task['train'][i]['input'])\n",
    "        img_out = np.array(task['train'][i]['output'])\n",
    "        \n",
    "        c_bg = common_bgcolor(img_in, img_out)\n",
    "        \n",
    "        oi_in = ObjectIndex(img_in, kernel = k_plus(), bg = c_bg)\n",
    "\n",
    "        oi_out = ObjectIndex(img_out, kernel = k_plus(), bg = c_bg)\n",
    "\n",
    "        ic = IdxComperator(oi_in, oi_out)\n",
    "        ic_list.append(ic)\n",
    "\n",
    "        if explain:\n",
    "            print(f'\\n### Describe Train{i} ###\\n')\n",
    "            for m in ic.interpreter():\n",
    "                print(m)\n",
    "\n",
    "\n",
    "    tc = task_comperator(ic_list)\n",
    "    \n",
    "    if explain:\n",
    "        print(f'\\n### Describe all tasks ###\\n')\n",
    "        for m in tc.interpreter():\n",
    "            print(m)\n",
    "    \n",
    "    \n",
    "    r = RuleDecoder(tc)\n",
    "    rule_pool = [RuleDecoder.r_cm_by_class_elem_cnt_rank,\n",
    "                 RuleDecoder.r_cm_by_class_elem_cnt,\n",
    "                 RuleDecoder.r_cm_class_id,\n",
    "                 RuleDecoder.r_palette_change\n",
    "                ]\n",
    "    rules = []\n",
    "    \n",
    "    # EVAL\n",
    "    for rule in rule_pool:\n",
    "        \n",
    "        if explain:\n",
    "                print(f'\\n### Eval rule on train:')\n",
    "                print(rule)    \n",
    "                \n",
    "        acc_cum = 0\n",
    "        for i in range(len(task['train'])):\n",
    "            # eval\n",
    "            img_in = np.array(task['train'][i]['input'])\n",
    "            img_out = np.array(task['train'][i]['output'])\n",
    "\n",
    "            #c_bg = common_bgcolor(img_in, img_out)\n",
    "            pred = r.predict(img_in, [rule], kernel = k_plus(), bg = c_bg)    \n",
    "            if isinstance(pred, np.ndarray):\n",
    "                acc = metrics.accuracy_score(img_out.reshape(1,-1)[0], pred.reshape(1,-1)[0])\n",
    "            else:\n",
    "                acc = 0\n",
    "            acc_cum += acc\n",
    "            \n",
    "            if acc != 1:\n",
    "                break\n",
    "        \n",
    "        if acc_cum / len(task['train']) == 1:\n",
    "            rules.append(rule)\n",
    "            if explain:\n",
    "                print(f'matching rule (acc = 100%)')\n",
    "        else:\n",
    "            if explain:\n",
    "                print(f'no matching rule')\n",
    "\n",
    "    # PRED\n",
    "    preds_flatt = {}\n",
    "    if len(rules) > 0:\n",
    "        for i in  range(len(task['test'])):\n",
    "            output_id = taskname+'_'+str(i)\n",
    "            print(f'Predicting {output_id} ...')\n",
    "            test_img_in = np.array(task['test'][i]['input'])\n",
    "            for rule in rules[:3]:\n",
    "                pred = r.predict(test_img_in,[rule], kernel = k_plus(), bg = c_bg)\n",
    "                if preds_flatt.get(output_id) == None:\n",
    "                    preds_flatt[taskname+'_'+str(i)] = flattener(pred.tolist())\n",
    "                else:\n",
    "                    preds_flatt[taskname+'_'+str(i)] = preds_flatt[taskname+'_'+str(i)] + ' ' + flattener(pred.tolist())\n",
    "                \n",
    "                if isinstance(pred, np.ndarray):\n",
    "                    print(f'\\nPredicted {taskname}')\n",
    "\n",
    "                    if is_training:\n",
    "                        acc = metrics.accuracy_score(np.array(task['test'][i]['output']).reshape(1,-1)[0], pred.reshape(1,-1)[0])\n",
    "                        print(f\"###EVAL accuracy: {acc}\")\n",
    "\n",
    "\n",
    "                if explain:\n",
    "                    print(f'\\n### Show predictions ###\\n')\n",
    "                    print(test_img_in, '\\n==>\\n', pred)\n",
    "                    if is_training:\n",
    "                        print('expected ==>\\n', np.array(task['test'][i]['output']))\n",
    "    elif explain:\n",
    "        print(f'no rules available for task {taskname}')\n",
    "    \n",
    "    return preds_flatt\n",
    "            \n",
    "## Test\n",
    "\n",
    "predTask('db3e9e38', explain = True, is_training = True) #b1948b0a #db3e9e38 #0d3d703e #08ed6ac7 #6e82a1ae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 it done\n",
      "Predicting 08ed6ac7_0 ...\n",
      "\n",
      "Predicted 08ed6ac7\n",
      "###EVAL accuracy: 1.0\n",
      "{'08ed6ac7_0': '|000000000|010000000|010002000|010002000|010002030|010002030|010402030|010402030|010402030|'}\n",
      "Predicting 67385a82_0 ...\n",
      "\n",
      "Predicted 67385a82\n",
      "###EVAL accuracy: 1.0\n",
      "{'67385a82_0': '|80803|88800|00003|08800|08800|'}\n",
      "Predicting 0d3d703e_0 ...\n",
      "\n",
      "Predicted 0d3d703e\n",
      "###EVAL accuracy: 1.0\n",
      "{'0d3d703e_0': '|954|954|954|'}\n",
      "Predicting 6e82a1ae_0 ...\n",
      "\n",
      "Predicted 6e82a1ae\n",
      "###EVAL accuracy: 1.0\n",
      "\n",
      "Predicted 6e82a1ae\n",
      "###EVAL accuracy: 1.0\n",
      "\n",
      "Predicted 6e82a1ae\n",
      "###EVAL accuracy: 0.96\n",
      "{'6e82a1ae_0': '|0000000001|0000000001|0011022001|0110002001|0000000000|0000000000|2000000000|2003300300|2000000300|0000000000| |0000000001|0000000001|0011022001|0110002001|0000000000|0000000000|2000000000|2003300300|2000000300|0000000000| |0000000001|0000000001|0055022001|0550002001|0000000000|0000000000|2000000000|2003300300|2000000300|0000000000|'}\n",
      "Predicting 810b9b61_0 ...\n",
      "\n",
      "Predicted 810b9b61\n",
      "###EVAL accuracy: 0.9027777777777778\n",
      "\n",
      "Predicted 810b9b61\n",
      "###EVAL accuracy: 0.9027777777777778\n",
      "{'810b9b61_0': '|000000011111|033330010001|030030010001|033330010001|000000011011|000000000000|011000000000|000011111000|010010001001|000010001000|000011111000|000000000000| |000000011111|033330010001|030030010001|033330010001|000000011011|000000000000|011000000000|000011111000|010010001001|000010001000|000011111000|000000000000|'}\n",
      "Predicting b1948b0a_0 ...\n",
      "\n",
      "Predicted b1948b0a\n",
      "###EVAL accuracy: 1.0\n",
      "\n",
      "Predicted b1948b0a\n",
      "###EVAL accuracy: 1.0\n",
      "{'b1948b0a_0': '|2772|2727|7772|7272| |2772|2727|7772|7272|'}\n",
      "Predicting b230c067_0 ...\n",
      "\n",
      "Predicted b230c067\n",
      "###EVAL accuracy: 0.86\n",
      "\n",
      "Predicted b230c067\n",
      "###EVAL accuracy: 0.75\n",
      "\n",
      "Predicted b230c067\n",
      "###EVAL accuracy: 0.75\n",
      "{'b230c067_0': '|0000000000|0220001110|0020000010|0100000800|0111008888|0000000000|0001110000|0000010000|0000800000|0008888000| |0000000000|0880008880|0080000080|0800000800|0888008888|0000000000|0008880000|0000080000|0000800000|0008888000| |0000000000|0880008880|0080000080|0800000800|0888008888|0000000000|0008880000|0000080000|0000800000|0008888000|'}\n",
      "Predicting b2862040_0 ...\n",
      "\n",
      "Predicted b2862040\n",
      "###EVAL accuracy: 0.8666666666666667\n",
      "{'b2862040_0': '|119999999999999|999999999991999|999111119991999|999919919991999|999919919991999|999911119991991|999999919991111|111199919991991|199199999999991|199199999999911|119999999999999|999999999999999|999111111999119|999199991999919|999199991999919|999111111199919|'}\n",
      "Predicting c8f0f002_0 ...\n",
      "\n",
      "Predicted c8f0f002\n",
      "###EVAL accuracy: 1.0\n",
      "{'c8f0f002_0': '|15515|81555|85158|'}\n",
      "Predicting d2abd087_0 ...\n",
      "\n",
      "Predicted d2abd087\n",
      "###EVAL accuracy: 0.92\n",
      "\n",
      "Predicted d2abd087\n",
      "###EVAL accuracy: 0.75\n",
      "{'d2abd087_0': '|0550002200|0550002200|5555022000|0000000000|0220000100|0222200100|0000000100|0000000100|0111110000|0000000000| |0550005500|0550005500|5555055000|0000000000|0550000100|0555500100|0000000100|0000000100|0555550000|0000000000|'}\n",
      "Predicting e8593010_0 ...\n",
      "\n",
      "Predicted e8593010\n",
      "###EVAL accuracy: 1.0\n",
      "\n",
      "Predicted e8593010\n",
      "###EVAL accuracy: 1.0\n",
      "\n",
      "Predicted e8593010\n",
      "###EVAL accuracy: 1.0\n",
      "{'e8593010_0': '|3555551155|5553551525|5515555525|5115555555|2555552555|2553552511|5525555515|5525555553|2255551555|5555351153| |3555551155|5553551525|5515555525|5115555555|2555552555|2553552511|5525555515|5525555553|2255551555|5555351153| |3555551155|5553551525|5515555525|5115555555|2555552555|2553552511|5525555515|5525555553|2255551555|5555351153|'}\n",
      "Predicting ea32f347_0 ...\n",
      "\n",
      "Predicted ea32f347\n",
      "###EVAL accuracy: 1.0\n",
      "{'ea32f347_0': '|0000000000|0002000000|0002000000|0002000000|0000000000|0000111111|0000000000|0000000000|4444400000|0000000000|'}\n",
      "Done!\n",
      "CPU times: user 42.4 s, sys: 187 ms, total: 42.6 s\n",
      "Wall time: 42 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "path=training_path #training_path #evaluation_path\n",
    "training_tasks = sorted(os.listdir(path)) #training_path\n",
    "training_tasks = [i.split('.')[0] for i in training_tasks]\n",
    "training_tasks = ['','08ed6ac7', '67385a82','0d3d703e', '63613498',\n",
    "                  '6e82a1ae', '810b9b61', 'b1948b0a',\n",
    "                  'b230c067', 'b2862040', 'c8f0f002',\n",
    "                  'd2abd087', 'ddf7fa4f', 'e509e548',\n",
    "                  'e8593010', 'ea32f347', '776ffc46']\n",
    "\n",
    "#training_tasks=['','ae58858e'] #['','ae58858e'] #,'ae58858e', 'e0fb7511']\n",
    "\n",
    "for i, t in enumerate(training_tasks[1:]):\n",
    "    #preds = predTask(t, path = path, is_training = True) # , is_training = True, explain= True) #evaluation_path\n",
    "        \n",
    "    if i%25 == 0:\n",
    "        print(f'{i} it done')\n",
    "    try:\n",
    "        preds = predTask(t, path = path, is_training = True) # , is_training = True, explain= True) #evaluation_path\n",
    "        for p in preds:\n",
    "            print(preds)\n",
    "    except:\n",
    "        None # print(f'Error in {t}')\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x288 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "taskname = '37d3e8b2' #'ae58858e'\n",
    "plot_task(taskname, path = evaluation_path) #training_path #evaluation_path)#, max_train=2)\n",
    "\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>output_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00576224_0</th>\n",
       "      <td>|32|78| |32|78| |00|00|</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>009d5c81_0</th>\n",
       "      <td>|00000000000000|00000888888888|00000800080808|...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00dbd492_0</th>\n",
       "      <td>|00000000000222220000|02222222220200020000|020...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03560426_0</th>\n",
       "      <td>|0000000000|0000000000|0000000000|0000000000|0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05a7bcf2_0</th>\n",
       "      <td>|000000000020000000080000000000|00000000002220...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       output\n",
       "output_id                                                    \n",
       "00576224_0                           |32|78| |32|78| |00|00| \n",
       "009d5c81_0  |00000000000000|00000888888888|00000800080808|...\n",
       "00dbd492_0  |00000000000222220000|02222222220200020000|020...\n",
       "03560426_0  |0000000000|0000000000|0000000000|0000000000|0...\n",
       "05a7bcf2_0  |000000000020000000080000000000|00000000002220..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "submission = pd.read_csv(data_path / 'sample_submission.csv', index_col='output_id')\n",
    "display(submission.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 it done\n",
      "Predicting 0a2355a6_0 ...\n",
      "\n",
      "Predicted 0a2355a6\n",
      "\n",
      "Predicted 0a2355a6\n",
      "25 it done\n",
      "Predicting 37d3e8b2_0 ...\n",
      "\n",
      "Predicted 37d3e8b2\n",
      "50 it done\n",
      "Predicting 1da012fc_0 ...\n",
      "\n",
      "Predicted 1da012fc\n",
      "75 it done\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "path=test_path\n",
    "test_tasks = set([s.split('_')[0] for s in submission.index.tolist()])\n",
    "\n",
    "for i, t in enumerate(test_tasks):\n",
    "    \n",
    "    if i%25 == 0:\n",
    "        print(f'{i} it done')\n",
    "    try:\n",
    "        preds = predTask(t, path = path)\n",
    "        for p in preds:\n",
    "            #print(preds.get(p))\n",
    "            submission.loc[p, 'output'] = preds.get(p)\n",
    "    except:\n",
    "        None#print(f'Error in {t}')\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>output_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00576224_0</th>\n",
       "      <td>|32|78| |32|78| |00|00|</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>009d5c81_0</th>\n",
       "      <td>|00000000000000|00000888888888|00000800080808|...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00dbd492_0</th>\n",
       "      <td>|00000000000222220000|02222222220200020000|020...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03560426_0</th>\n",
       "      <td>|0000000000|0000000000|0000000000|0000000000|0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05a7bcf2_0</th>\n",
       "      <td>|000000000020000000080000000000|00000000002220...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       output\n",
       "output_id                                                    \n",
       "00576224_0                           |32|78| |32|78| |00|00| \n",
       "009d5c81_0  |00000000000000|00000888888888|00000800080808|...\n",
       "00dbd492_0  |00000000000222220000|02222222220200020000|020...\n",
       "03560426_0  |0000000000|0000000000|0000000000|0000000000|0...\n",
       "05a7bcf2_0  |000000000020000000080000000000|00000000002220..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(submission.head())\n",
    "\n",
    "submission.to_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
